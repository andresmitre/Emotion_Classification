	{
	 "cells": [
	  {
	   "cell_type": "markdown",
	   "metadata": {},
	   "source": [
		"# Emotion Classification\n",
		"**Module 3: Data acquisition**\n",
		"* Author: [Andrés Mitre](https://github.com/andresmitre), [Center for Research in Mathematics (CIMAT)](http://www.cimat.mx/en) in Zacatecas, México.\n"
	   ]
	  },
	  {
	   "cell_type": "markdown",
	   "metadata": {},
	   "source": [
		"Module   |Title\n",
		"---------|--------------\n",
		"Module 1 |[Introduction](https://github.com/andresmitre/Emotion_Classification/blob/master/introduction.ipynb)\n",
		"Module 2 |[Haar Cascade Algorithm](https://github.com/andresmitre/Emotion_Classification/blob/master/Haar_Feature_based_Cascade_Classifiers.ipynb)\n",
		"Module 3 |[Data acquisition](https://github.com/andresmitre/Emotion_Classification/blob/master/data_acquisition.ipynb)\n",
		"Module 4 |[Regression Neural Network](https://github.com/jeffheaton/t81_558_deep_learning/blob/master/assignments/assignment_yourname_class4.ipynb)\n",
		"Module 5 |[Time Series Neural Network](https://github.com/jeffheaton/t81_558_deep_learning/blob/master/assignments/assignment_yourname_class10.ipynb)\n"
	   ]
	  },
	  {
	   "cell_type": "markdown",
	   "metadata": {},
	   "source": [
		"# Goals\n",
		"\n",
		"*  Capture RAW data from FER and GSR.\n",
		"*  Export data to a CSV file.\n"
	   ]
	  },
	  {
	   "cell_type": "markdown",
	   "metadata": {},
	   "source": [
		"# Raw Data\n",
		"\n",
		"The data collection, starts with a FER(Facial Expression Recognition) using [haarcascades](https://github.com/opencv/opencv), with a professional camera/webcam. Images were taken while 23 participants watched a series of films related with emotions. The images were saved into separate emotions folders. GSR lectures were recorded as well since stress and boredom emotions stimulates the activity of sweet glands. the GSR were captured with the [Grove - GSR sensor](https://www.seeedstudio.com/Grove-GSR-sensor-p-1614.html) and saved into a CSV file. \n",
		"\n",
		"**Galvanic Skin Response (GSR)**\n",
		"\n",
		"It is important to represent the data in a way that the neural network can train from it.  In class 6, we will see even more ways to preprocess data.  For now, we will look at several of the most basic ways to transform data for a neural network.\n",
		"\n",
		"The Galvanic Skin Response (GSR) is defined as a change in the electrical properties of the skin. The signal can be used for capturing the autonomic nerve responses as a parameter of the sweat gland function. The measurement is relatively simple, and has a good repeatability. Therefore the GSR measurement can be considered to be a simple and useful tool for examination of the autonomous nervous system function, and especially the peripheral sympathetic system.\n",
		"\n",
		"For detailed information I highly reccomend to check [The complete pocket guide by IMOTIONS](https://imotions.com/guides/).\n",
		"\n",
		"* Materials required:\n",
		"    * **Camera** - [EOS Rebel T3 – Canon Profesional.](https://www.amazon.com/Canon-Digital-18-55mm-discontinued-manufacturer/dp/B004J3Y9U6).\n",
		"    * **Monitor** - [LCD 22 in, TFT FPD2275W-MX](https://www.cnet.com/products/gateway-fpd2275w/specs/).\n",
		"    * **Keyboard** - DELL SK-8115.\n",
		"    * **Speakers** - Subwoofer DELL A525.\n",
		"    * **GSR Sensor** - [Grove - GSR Sensor](https://www.seeedstudio.com/Grove-GSR-sensor-p-1614.html).\n",
		"    * **Computer** - [Dell Inspiron 13-7359 Signature Edition](http://www.dell.com/en-us/shop/dell-laptops/new-inspiron-13-7000-series-2-in-1-laptop/spd/inspiron-13-7359-laptop).\n",
		"* Films Stimulants:\n"
	   ]
	  },
	  {
	   "cell_type": "markdown",
	   "metadata": {},
	   "source": [
		"Emotion   |Film                |Director\n",
		"---------|---------------------|--------\n",
		"Neutral  |The Lover            |Jean-Jacques Annaud\n",
		"Happy    |When Harry Met Sally |Rob Reiner\n",
		"Stress   |Irreversible         |Gaspar Noé\n",
		"Boredom  |Amateur film         |[Merrifield, C. and Danckert, J.](https://www.youtube.com/watch?v=s34zGmq3rXQ)\n"
	   ]
	  },
	  {
	   "cell_type": "markdown",
	   "metadata": {},
	   "source": [
		"# Procedure\n",
		"\n"
		]
	  },
	  {
	   "cell_type": "code",
	   "execution_count": 1,
	   "metadata": {},
	   "source": [
		"import numpy as np\n",
		"import cv2 as cv\n",
		"\n",
		"face_cascade = cv.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
		"eye_cascade = cv.CascadeClassifier('haarcascade_eye.xml')\n",
		"\n",
		"img = cv.imread('sachin.jpg')\n",
		"gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)"
	   ]
	  },
	   {
	   "cell_type": "markdown",
	   "metadata": {},
	   "source": [
		"Now we find the faces in the image. If faces are found, it returns the positions of detected faces as Rect(x,y,w,h). Once we get these locations, we can create a ROI for the face and apply eye detection on this ROI (since eyes are always on the face !!! ).\n",
		"\n"   
	   ]
	  },
	  {
	   "cell_type": "code",
	   "execution_count": 2,
	   "metadata": {},
	   "source": [
		"faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
		"for (x,y,w,h) in faces:\n",
		"    cv.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
		"    roi_gray = gray[y:y+h, x:x+w]\n",
		"    roi_color = img[y:y+h, x:x+w]\n",
		"    eyes = eye_cascade.detectMultiScale(roi_gray)\n",
		"    for (ex,ey,ew,eh) in eyes:\n",
		"        cv.rectangle(roi_color,(ex,ey),(ex+ew,ey+eh),(0,255,0),2)\n",
		"cv.imshow('img',img)\n",
		"cv.waitKey(0)\n",
		"cv.destroyAllWindows()"
	   ]
	  },
	  {
	   "cell_type": "markdown",
	   "metadata": {},
	   "source": [
	   "## Additional Resources\n",
	   "\n",
	   "Video Lecture on [Face Detection and Tracking](https://www.youtube.com/watch?v=WfdYYNamHZ8).\n",
	   "\n"  
	   ]
	  },
	  {
	   "cell_type": "markdown",
	   "metadata": {},
	   "source": [
		"In order to use different classifiers for face, eyes, smiles and upper body. OpenCV has several XML files, try some of these [here](https://github.com/opencv/opencv/tree/master/data/haarcascades).\n",
		"\n"   
	   ]
	  }
	 ],
	 "metadata": {
	  "anaconda-cloud": {},
	  "kernelspec": {
	   "display_name": "Python 3",
	   "language": "python",
	   "name": "python3"
	  },
	  "language_info": {
	   "codemirror_mode": {
		"name": "ipython",
		"version": 3
	   },
	   "file_extension": ".py",
	   "mimetype": "text/x-python",
	   "name": "python",
	   "nbconvert_exporter": "python",
	   "pygments_lexer": "ipython3",
	   "version": "3.6.3"
	  }
	 },
	 "nbformat": 4,
	 "nbformat_minor": 1
	}
